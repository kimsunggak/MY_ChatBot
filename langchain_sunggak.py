import streamlit as st
import openai
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_community.chat_models import ChatOpenAI

@st.cache_resource
def load_and_embed_pdfs():
     # PDF íŒŒì¼ ë¬¸ì„œ ë¡œë“œ
    pdf_loader = DirectoryLoader('.', glob="*.pdf")
    # ë¡œë“œí•œ ë¬¸ì„œ documentsì— ì €ì¥
    documents = pdf_loader.load()
     # í…ìŠ¤íŠ¸ë¥¼ íŠ¹ì • í¬ê¸°ë¡œ ë‚˜ëˆŒ ë•Œ ë¬¸ë§¥ ìœ ì§€ì™€ ì •ë³´ ì†ì‹¤ ë°©ì§€ë¥¼ ìœ„í•´ overlap ì ìš©
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    texts = text_splitter.split_documents(documents)

     # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
    embedding = OpenAIEmbeddings(openai_api_key=st.session_state["OPENAI_API"])
    # ë‚˜ëˆ ì§„ í…ìŠ¤íŠ¸ ë©ì–´ë¦¬ë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜í•œ í›„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    vectordb = Chroma.from_documents(documents=texts, embedding=embedding)

    return vectordb

def main():
    # ê¸°ë³¸ í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="ìˆ˜ê°•ì‹ ì²­ ì±—ë´‡",
        layout="wide",
        page_icon="https://search.pstatic.net/sunny/?src=https%3A%2F%2Fwww.shutterstock.com%2Fimage-vector%2Fhuman-brain-icon-simple-outline-260nw-2140916827.jpg&type=ff332_332"
        
    )
# CSS ìŠ¤íƒ€ì¼ì„ ì‚¬ìš©í•˜ì—¬ ë°°ê²½ìƒ‰ ë³€ê²½
    st.markdown(
        """
        <style>
        body {
            background-color: blue;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.title("ìˆ˜ê°•ì‹ ì²­ ì±—ë´‡")

    st.header("")
    st.markdown("""
      ë‹µë³€ ì˜ˆì‹œ)
    - ì¸ê³µì§€ëŠ¥ìœµí•©ê³µí•™ë¶€ì—ëŠ” ì–´ë–¤ ì „ê³µê³¼ëª©ë“¤ì´ ìˆëŠ”ì§€ ì•Œê³ ì‹¶ì–´ O
    - ìˆ˜ê°• ì‹ ì²­ ê¸°ê°„ì€ ì–¸ì œì¸ê°€ìš”? O
    - êµìˆ˜ë‹˜ë“¤ ì—°ë½ì²˜ë¥¼ ì•Œë ¤ì¤˜ X 
    - ì „ê³µê³¼ëª©ì„ ì•Œë ¤ì¤˜ X
    """)
    # OpenAI_API í‚¤ ì…ë ¥ë°›ëŠ” ì‚¬ì´ë“œë°” ìƒì„±
    with st.sidebar:
        st.session_state["OPENAI_API"] = st.text_input(label="OPENAI APIí‚¤", placeholder="ë‹¹ì‹ ì˜ API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.", value="", type="password")
        st.markdown("---")
        model = st.radio(label="GPT ëª¨ë¸", options=["gpt-4o", "gpt-3.5-turbo"])
        st.markdown("---")

    # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "ìˆ˜ê°•ì‹ ì²­ì— ê´€ë ¨í•˜ì—¬ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!"}]

    # ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ ìˆœíšŒí•˜ì—¬ ê° ë©”ì‹œì§€ë¥¼ í‘œì‹œ
    for msg in st.session_state.messages:
        if msg["role"] == "assistant":
            icon = "ğŸ¤–"  # ë´‡ ì•„ì´ì½˜
        else:
            icon = "ğŸ§‘â€ğŸ’»"  # ì‚¬ìš©ì ì•„ì´ì½˜      
        st.markdown(f"{icon} {msg['content']}")
        # ë´‡ì˜ ë©”ì‹œì§€ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥
        
    # chat_input í•¨ìˆ˜ë¡œ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ì…ë ¥ë°›ìŒ
    if prompt := st.chat_input():
        # OpenAI_APIí‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì€ ê²½ìš°
        if not st.session_state["OPENAI_API"]:
            st.info("OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!!")
            st.stop()

        # openai í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = openai.OpenAI(api_key=st.session_state["OPENAI_API"])
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ session_state ë©”ì‹œì§€ì— ì¶”ê°€í•˜ê³  í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        
        vectordb = load_and_embed_pdfs()
        retriever = vectordb.as_retriever()

        qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=st.session_state["OPENAI_API"]),
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True)
        
        response = qa_chain.invoke(prompt)
        msg = response['result']
        # ì‘ë‹µ ìƒì„±í›„ ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.messages.append({"role": "assistant", "content": msg})
        st.chat_message("assistant").write(msg)

if __name__ == "__main__":
    main()
